seed: 42
exp_name: test
valid_size: 64
batch_size: 4
eval_batch_size: 8
debug: false
fsdp_port: null
wandb:
  enabled: true
  entity: null
  project: dpo-toxicity-pplm
local_dirs:
- .cache
n_eval_model_samples: 16
do_first_eval: false
local_run_dir: ${get_local_run_dir:${exp_name},${local_dirs}}
lr: 1.0e-06
gradient_accumulation_steps: 1
max_grad_norm: 10.0
max_length: 256
max_new_tokens: 64
max_prompt_length: 64
n_epochs: 5
trainer: BasicTrainer
optimizer: RMSprop
warmup_steps: 150
activation_checkpointing: false
eval_every: 100
save_every: 100
validation_metric: loss/valid
validation_direction: min
validation_patience: 30
sample_during_eval: false
sample_every: 2000
minimum_log_interval_secs: 2.0
model:
  name_or_path: gpt2-medium
  tokenizer_name_or_path: null
  archive: null
  block_name: GPT2Block
  policy_dtype: float32
  fsdp_policy_mp: null
  reference_dtype: float16
loss:
  name: dpo
  beta: 0.1
  reference_free: false
